version: '3.8'

services:
  # simple api 
  prediction-api:
    build: ./src
    command: uvicorn app.main:app --reload --workers 1 --host 0.0.0.0 --port 8000
    deploy:
      replicas: 5
    volumes:
      - ./src/:/usr/src/app/
    ports:
      - "8000"
    depends_on:
      - fuel-consumption
    networks:
      - "ml-network"

  # nginx reverse proxy providing load balancing for prediction api.   
  proxy:
    image: nginx:latest
    container_name: prediction-proxy
    volumes:
      - ./proxy/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on: 
      - prediction-api
    ports: 
      - "3000:80"
    networks: 
      ml-network:
        aliases:
          - proxy

  # machine learning prediction model using tensor flow.
  fuel-consumption:
    image: tensorflow/serving
    container_name: mpg_prediction
    ports:
      - "8500:8500"
      - "8501:8501"
    volumes:
      - ./fuel-consumption/model:/models
      - ./fuel-consumption/serving_docker.config:/models/serving_docker.config
    command: --model_config_file=/models/serving_docker.config
    networks:
      - ml-network

networks:
  ml-network:
